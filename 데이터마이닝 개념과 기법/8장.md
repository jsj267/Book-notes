### 8. 클래스 분류 : 기초 개념과 방법

#### 8.1 기본 개념
- 분류 모델 : 라벨(클래스)를 예측
- 데이터 클래스 분류 과정
	+ 학습 : 분류 알고리즘을 통해 훈련 데이터를 분석.
	+ 분류 : 테스트 데이터로 분류 규칙(모델)의 정확성을 평가. 정확도가 일정 이상일 경우, 새로운 데이터를 분류에 적용한다.
- 훈련 데이터의 클래스 라벨이 있는/없는 경우
	+ 지도 학습(Supervice Learning) : 라벨이 있는 경우.
	+ 비지도 학습(Unsuperviced learning) : 라벨이 없는 경우. 분류와 가짓수도 미정일 때. = 클러스터링 기법
- 분류 정확도를 확인할 때, 훈련 데이터로 정확성을 측정할 경우 모델이 데이터에 과적합(Overfitting)할 수 있기 때문에 실제 데이터에 대한 정확도는 이보다 낮다. 따라서 훈련 데이터와는 별도의 테스트 데이터 튜플을 구성해야한다.

#### 8.2 결정 트리(Decision Tree) 유도
- 결정 트리 유도 : 훈련 세트를 바탕으로 결정 트리를 학습하는 기법
- 리프 노트가 아닌 내부 노드에서 속성값을 테스트하고, 테스트 결과에 따라 분기해서 클라스 라벨(=리프 노드)을 결정짓는 트리 구조.
- 장점
	+ 대상 분야에 대한 배경 지식과 파라미터 조정이 필요하지 않다. (즉, 결정 트리의 성공 여부는 훈련데이터에 따라 달려있다.)
	+ 다타원 데이터를 처리할 수 있다.
	+ 트리 구조가 단순하면서 이해하기 쉽다.
	+ 학습과 분류가 빠르고 정확도도 좋은 편.
- 속성 A 에 따라 분기 유형이 3가지
	+ A가 불연속 값(a1, a2, ...)일 때 파티션 : A = a1, A=a2, ...
	+ A가 연속 값일 때 파티션 : A <= split_point, A > split_point
	+ A가 불연속 값 속성이면서 이진 트리를 작성해야 하는 경우 파티션 : yes / no

1. 속성 선택 방법(=분할 규칙)
	- 훈련 데이터 튜플 세트를 가장 잘 분할해 주는 분할 기준을 찾아주는 휴리스틱.
	- 훈련 데이터 세트를 가장 순수한(각 파티션에 포함된 튜플이 가능한 모두 같은 클래스에 해당하도록) 부분 집합으로 쪼개기 위함.
	- 3가지 방법
		+ 정보 소득
			- 정보 소득이 가장 높은 속성이란, 분할하는 데 필요한 정보가 가장 적은 속성. 임의성이 가장 적고 결과 파티션의 불순함이 가장 낮은 속성.
			- 파티션 D를 분류하는 데 필요한 정보양의 기대값은 *Info(D) = -SUM(Pi * log2(Pi)), i=1, ..., m* = 엔트로피
			- 엔트로피 값이 작다 = 분류하는 데 필요한 정보양이 작다 = 불순도가 낮다 = 임의성이 작다 = 순수한 파티션
			- 속성A로 분기했을 때 엔트로피는 *InfoA(D) = sum(파티션 j의 분할 전과 분할 후 레코드 비율 * Info(Dj))*
			- *Info(D)* > *InfoA(D)* 이면 분할함으로써 엔트로피 값이 작아짐.
			- 정보 소득 *Gain(A) = Info(D) - InfoA(D)*, 즉 A 속성으로 분기했을 때 어느 정도의 소득을 벌충할 수 있는가를 뜻한다.
			- A 속성값을 알게 됨으로써 필요한 정보량 기대치가 줄어들었기 때문.
			- 정보 소득 *Gain(A)* 가 가장 큰 속성을 분기 속성으로 선택한다.
			- 속성 A가 연속 속성일 경우, A의 값 v개를 오름차순 정렬한 후. 각 값 사이의 중점을 후보 지점(split point)로 지정.
			- 각 후보 지점을 기준으로 파티션을 나눠서 정보 소득을 계산한다.
			- v-1 개의 모든 후보 지점에 대해서 Gain(A)를 계산하고, Gain(A)가 가장 큰 값을 갖는 지점을 split point로 설정하여 분할.
			- 값이 다양한 속성에 기우는 단점.
			- ID3 알고리즘
		+ 소득 비율
			- 정보 소득을 발전시킨 정보 소득율(Gain Ratio)은 정보 소득의 잘못된 경향성을 보정한다.
			- 정보 소득은 모든 파티션의 크기가 균일하다고 가정하는데, 소득율은 파티션 크기를 고려한다.
			- 그러나 파티션 크기 차이가 큰 불균형적인 분할을 만들기 쉽다는 단점
			- *GainRatio(A) = Gain(A) / SplitInfoA(D)*
			- C4.5 알고리즘
		+ 지니 계수
			- 훈련 튜플 세트를 파티션으로 나누었을 때, D의 불순한 정도
			- *Gini(D) = 1 - SUM(Pi^2), 단 i=1, ..., m*
			- 줄어든 불순함의 정도 *Delta(Gini(A)) = Gini(D) - GiniA(D)*
			- 지니 계수는 모든 속성의 이진분할을 전제로 계산한다. 정보소득처럼 여러 갈래의 분할(속성 A가 여러개의 불연속적인 값을 가질 때, A=a1, A=a2, ...이런 식으로 나누지 않고, A가 {a1, a2, ...}에 속하냐 속하지않느냐(yes/no)의 방법으로 계산해야한다.)
			- 값이 다양한 속성을 택할 가능성이 높고, 클래스 구분이 여러개 있을 경우 계산이 어려움. 균형 분할을 선호하는 단점.
			- CART(Classification and regression trees) 알고리즘
		+ 기타 속성 방법
			- CHAID(카이제곱 테스트 통계기법을 활용)
			- C-SEP
			- G-statistics
			- MDL(Minimum Description Length 최소서술거리) 원리에 기반하여 다수 속성이 있을 때 가장 편향이 적은 속성을 선택
			- 단일 속성이 아닌 여러 속성 조합을 통해 분할하는 다변수 분할 계열 속성 선택 방법도 존재.

2. 가지치기(Pruning)
	- 과적합 문제를 해결하기 위한 기법.
	- 2가지 기법
		+ 미리치기(Prepruning)
			* 트리를 구성하다가 분류 결과가 어떤 기준을 만족하지 못하면 더 이상의 분류를 진행하지 않는 것.
			* 통계적 유의성, 정보 소득, 지니 계수 등 측정값이 분류 기준이 될 수 있다.
			* 물론 적당한 수준의 역치(Threshold)를 선택하는 어려움이 있다.
		+ 나중치기(Postpruning)
			* 트리를 다 만든 후 부분 가지를 제거하는 방법
			* 부분 트리를 그 부분 트리에서 가장 많이 등장하는 클래스로 말단 리프 노드로 대체.
			* 비교적 널리 활용되는 방법
			* CART 기법의 비용 복잡도 가지치기 알고리즘 : 별도의 가지치기 데이터 셋으로 계산			
				![Cost function](https://github.com/jsj267/Data-Mining/blob/master/picture/%EC%BA%A1%EC%B2%98.JPG?raw=true)
			* C4.5 알고리즘의 방어적 가지치기 기법 : 기존 훈련 데이터 셋을 통해 에러율 측정
			* 트리를 코드화 했을 때 필요한 비트 숫자를 기준으로 가지를 솎아내는 방법. 필요 비트가 적을 수록 잘 분류된 트리.

3. 결정 트리 유도와 규모
	- 초기 결정 트리는 훈련 데이터보다 메모리 공간이 더 커서 메모리에서 계산했으나 훈련 데이터 세트가 커져 어려움이 있었다.
	- 레인포레스트(RainForest)
		+ 트리 노드의 분기 속성을 AVC세트(속성Attribute - 값Value - 라벨Class label)의 형식으로 저장해서 노드에 연결된 훈련 튜플을 저장한다.
	- BOAT(Bootstrapped Optimistic Algorithm for Tree Construction 트리 구성 부트스트랩 최적화 알고리즘)
		+ 데이터 구조를 전제하지 않는다.
		+ 부트스트랩Bootstrap 통계 기법으로 주어진 훈련 데이터를 메모리에 들어갈만큼 작은 샘플 부분집합으로 나누어 처리한다.
		+ 매 샘플 부분집합마다 결정 트리를 구성해서 여러개의 트리를 비교, 대조하면서 최종 결정 트리를 만들어 반환한다.

4. 결정 트리를 눈으로 보기
	- PBC(perception-based Classification 인지 기반 클래스 분류)
		+ 결정 트리를 만드는 과정에서 데이터를 눈으로 보면서 확인할 수 있는 인터랙션 결정 트리 유도 도구.

#### 8.3 베이즈 분류
1. 개념
	- Bayesian Classifier 베이지안 분류자
		+ 통계적 분류자.
		+ 해당 튜플이 특정 클래스에 들어갈 가능성을 계산하여 클래스 배정 확률을 예측
		+ 대규모 데이터베이스에 적용했을 때, 높은 정확성과 빠른 속도를 장점으로 가진다.

2. 베이즈 이론
	- 토마스 베이즈의 이름을 딴 이론
	- 훈련 데이터 튜플을 X, 특정 클래스를 C, X가 C에 속한다는 가설을 H라고 하자.
	- 우리가 궁금한 것은 튜플 X가 클래스 C에 속할 확률이다.
	- 이는 X는 H의 증거이므로, P(H|X) : 'X라는 증거를 확인한 가설 H가 참일 확률'과 같다.
	- 베이즈 이론을 이용하여 P(H|X)(=조건부 확률Posterior probability, 귀납적 확률)를 밑의 식으로 구한다.
	- P(H|X) = P(X|H) * P(H) / P(X). (단, P(H)는 사전 확률Prior probability, 연역적 확률이라고 한다.)

3. 나이브 베이지안 분류자 Naive Bayesian classifier (=단순 베이지안 분류자)
	- '나이브'라는 이름이 붙은 이유는 클래스 조건부 독립성이 계산을 단순화하기 때문이다.
	- 작동 방식은 다음과 같다.
		+ 베이즈 이론 P(H|X) = P(X|H) * P(H) / P(X) 식을 이용한다.
		+ 분류자는 조건부 확률 P(Ci|X)가 가장 큰 클래스 Ci로 튜플을 분류하므로 P(Ci|X)가 최대인 경우를 찾는다.
		+ P(X)는 상수
		+ 클래스의 사전 확률이 동일한 가능성을 갖는다면 P(Ci)는 상수. 또는 사전확률 P(Ci)를 training set으로부터 추정치를 계산한다. 사전 확률이 동일하지 않다면 P(X|Ci)P(Ci)가 최대인 경우를 찾아야한다.
		+ 그렇다면 P(X|Ci)가 최대가 되는 Ci를 구하면 되는데, 이 값을 구하기 위해 클래스 조건 독립성(Class-conditional independence)을 전제로 한다.
		+ 클래스 조건부 독립성 : 하나의 속성 값이 튜플의 라벨 결정에 대해 다른 속성의 영향을 받지 않는다는 것. 즉 속성 사이에 의존 관계가 없다.
		+ 클래스 조건부 독립성에 의해 P(X|Ci) = P(x1|Ci) x ... x P(xn|Ci) 가 성립하고 확률값을 구할 수 있다.
		+ P(xk|Ci)=0 인 경우, 훈련 데이터 크기가 충분히 크다면 라플라시안 보정을 통해 모든 속성마다 하나의 가상 튜플을 더해 확률값이 0이 되는 것을 피하여 계산한다.
		+ 최종적으로 P(X|Ci)P(Ci)을 계산하여 이 값이 최대가 되는 클래스 Ci를 해당 클래스로 분류한다.
	- 베이지안 분류자 사용이 어려운 2가지 경우(=베이지안 분류자의 가정이 성립하지 않는 경우)
		+ 클래스 조건부 독립성이 만족하지 않는 경우. P(X|Ci) 계산이 어렵기 때문이다. 그럼에도 불구하고 예측력이 좋아서 무시하고 사용하는 편. 물론 예측력을 높이려면 변수간의 의존성을 줄이는 것이 좋다.
		+ 확률을 검증할 수 있는 데이터가 부족한 경우. 그래서 위에서 대규모 데이터베이스에 적용했을 때 높은 정확성을 가진다고 한 듯.

#### 8.4 규칙 기반 클래스 분류
1. IF-THEN 규칙
	- IF (선행 규칙 또는 전제 조건) THEN (규칙 결론)
	- 데이터 세트 D, 튜플 X, 규칙 R 이라고 할 때,
	- IF-THEN 규칙을 만족하면, '해당 튜플이 선행 조건을 충족한다' 또는 '해당 튜플이 규칙을 촉발한다' 또는 '규칙이 튜플을 포괄한다'고 한다.
	- 어떤 튜플이 충족하는 규칙이 하나뿐이라면, 규칙을 발행해서 튜플의 클래스 라벨을 반환한다.
	- 규칙 R의 포괄범위와 정확도 (단, Ncovers는 D에서 R을 적용하는 튜플의 개수, Ncorrect는  Ncovers중 R을 만족하는 튜플의 개수)
		+ 포괄범위 => coverage(R) = Ncovers / |D|
		+ 정확도 => accuracy(R) = Ncorrect / Ncovers
	- 발생하는 문제 2가지
		+ 튜플 X가 하나 이상의 규칙을 만족할 때, 경합 해소 전략(Conflict Resolution Strategy)
			* 규모 정렬(Size ordering)
				- 조건이 가장 '까다로운' 규칙에 최우선권을 부여.
				- 전제 조건의 크기, 즉 속성 테스트의 개수가 많을수록 까다롭다고 한다.
				- 규칙과 규칙 사이의 관계가 합집합 관계. 규칙 사이에 순서가 존재하지 않음.
			* 규칙 정렬(Rule ordering)
				- 사전에 클래스 또는 규칙의 우선 순위를 결정한다.
				- 클래스 기준 정렬 : 클래스의 우선 순위를 결정
					- 보통 클래스 기준 정렬을 사용한다.
					- 훈련 데이터에서의 튜플 분포도에 따라 중요도 순으로 클래스의 순위를 결정.
					- 규칙 적용 결과 중 높은 순위를 가진 클래스를 선택.
				- 규칙 기준 정렬 : 규칙의 우선 순위를 결정.
					- 규칙을 품질 지표 또는 전문가 조언에 따라 우선순위 목록으로 정렬.
					- 이 때, 규칙 세트를 결정 목록이라고 한다.
		+ 튜플 X가 충족하는 규칙이 하나도 없을 때
			* 훈련 세트를 기준으로 기본 클래스(Default class)를 반환하는 기본 규칙을 적용.
			* 기본 클래스는 훈련 데이터에서 가장 많이 등장하거나 훈련 데이터에서 규칙을 벗어나는 튜플이 가장 많이 있는 클래스로 설정한다.
2. 결정 트리에서 규칙 추출
	- 결정트리는 규모가 늘어나면 해석이 어렵다는 단점이 있음.
	- 결정 트리에서 IF-THEN 규칙을 추출해서 규칙 분류자를 구성하는 방법이 있다.
	- 결정트리를 구성했을 때, 루트 노드에서 리프노드까지의 하나의 경로를 하나의 규칙으로 설정한다. 그 경로는 전제조건이 되고, 해당 리프노드가 결론이 된다.
	- 각 규칙들은 상호배타적이고 완결적(하나의 튜플을 포괄하는 최소 하나의 규칙이 존재).
	- 이 결정 트리에서도 가지치기가 가능하다. 규칙의 정확성을 향상시키지 못하는 규칙을 삭제하는 방향으로.
	- 그러나 배타성과 완결성이 보장되지 않아 C4.5에서는 클래스 기준 정렬 방식을 사용.

3. 순차 포괄 알고리즘(Sequential Covering Algorithm)의 규칙 구성
	- 순차 포괄 알고리즘 : 규칙을 순서대로, 한번에 하나의 규칙을 학습한다. IF절을 구체화시켜가는 과정.
	- ![순차 포괄 알고리즘](https://github.com/jsj267/Data-Mining/blob/master/picture/learn-one-rule.png?raw=true)
	1) 하나의 클래스에 대해 THEN 결론을 구성. ex) IF THEN PlayTennis="yes"
	2) IF에 추가할 속성 테스트를 결정하자.
		- 위 알고리즘 그림처럼 모든 경우를 고려해서 그 중 하나를 선택하기보다 Greedy 방식의 깊이 우선 전략을 선택한다.(그래서 순서대로 한번에 하나씩 규칙을 학습하는 것)
		- Greedy 방식은 복기(Backtracking)가 없다. Greedy방식은 최적의 방식 1개를 선택하는데, K개의 속성 테스트 후보를 선택하는 K-폭 빔 탐색 기법을 사용할 수도 있다.
		- 규칙의 품질을 가장 많이 향상시킬 수 있는 조건을 속성테스트에서 찾아(3-1) 선택한다.
		- 규칙은 속성테스트를 추가할수록 더 많은 해당 클래스 튜플들을 포함해야한다.(더 많은 튜플이라고 워딩이 되어있어 개수를 의미하는 것으로 생각했는데, 규칙의 품질이 정확성 뿐만 아니라 포괄범위도 고려하기 때문에 속성 테스트를 추가할수록 품질이 높아진다고 하는 것이 정확해보인다.)
	3) 종료 조건을 만족할 시 종료
		- 종료조건 1. 남아있는 훈련 튜플이 없는 경우
		- 종료조건 2. 규칙의 품질이 지정했던 수준보다 낮을 경우.

- 3-1. 규칙 품질 측정법
	- 규칙의 품질은 규칙의 정확성뿐만 아니라 포괄 범위를 종합해서 판단해야한다.
	1) 엔트로피(=튜플 D를 분류하는데 필요한 정보의 기댓값)
	2) FOIL(First order inductive learner); 일차 귀납 학습자
		- 정보 소득에 바탕을 둔다.
		- FOIL_Gain = pos' * (log2(pos'/(pos'+neg') -  log2(pos/(pos+neg))
		- 단, pos(neg)는 규칙 R에 해당하는 긍정(부정) 튜플 개수. pos'(neg')는 규칙 R에 해당하는 튜플 개수.
	3) 통계적으로 검증하는 방법
		- 규칙이 포괄하는 튜플의 클래스 분포와 랜덤으로 예측 규칙을 만들었을 때의 분포를 비교한다.
		- 이 차이가 우연인지 유의미한지를 Likelihood ratio statistics 가능성비 검정으로 확인한다.
		- Likelihood_Ratio = 2 * SUM(Fi * log(Fi/Ei)) ~ x^2(m-1)
		- 단, m=클래스 개수, i=1,...,m이고, Fi=튜플의 클래스 해당 비율, Ei=무작위 규칙 클래스 예상 비율
		- 가능성비 값이 클수록 해당 규칙이 랜덤 규칙보다 더 품질이 좋다는 것을 의미한다.

- 3-2. 규칙 가지치기
	- 규칙에서 조건(속성 테스트)를 제거했을 때, 훈련 데이터와 독립적인 튜플 세트에서 R보다 나은 품질이 확인되면 조건을 제거하는 방식으로 규칙을 가지치기한다.
	- 가지치기 방법 중 FOIL을 이용하는 방법은 다음과 같다.
		+ FOIL_Prune(R) = (pos-neg)/(pos+neg)
		+ FOIL_Prune값은 R의 정확성과 비례한다.
		+ R을 가지치기 했을 때 FOIL_Prune값이 높아진다면 좋은 가지치기라고 볼 수 있다.
		+ RIPPER 순차 포괄 알고리즘은 FOIL과 가장 늦게 추가한 조건부터 가지치기 여부를 검사한다.

#### 8.5 모델 검증과 선택
1. 분류자 성능 비교 측정법
	- 생각해볼 문제1 : 분류자가 튜플의 클래스 라벨을 얼마나 잘, 정확하게 예측하는지 확인하기 위한 지표에는 무엇이 있는가.
		+ 정확성(오차율), 민감성, 특이성, 정밀도, 반환율, F측정법, Fbeta측정법 등
	- 생각해볼 문제2 : 클래스 튜플 분포가 불균형할 경우(또는 훈련 데이터와 비교했을 때 균등 정도가 다를 때) 성능 비교는 어떻게 해야하는가.
		+ 클래스가 불균등할 경우, 즉 일부 클래스가 희박하게 등장하는 경우 ex) 암 환자, 사기 감시 프로그램.
		+ 암 환자 예측 분류자의 정확도가 97%인 경우, 암 환자가 3%이고 전부 암환자가 아닐것이라고 분류하면 정확도 97%를 얻는다.
		+ 따라서 정확성이 아닌 다른 지표가 필요.
		+ 클래스의 분포 정도가 비교적 균일한 경우 정확성을, 불균등하다면 민감성, 특이성, 정밀도, 반환율, F측정법, Fbeta측정법 등
	- 생각해볼 문제3 : 모든 튜플은 단 하나의 클래스에 소속되는가.
		+ 이 지표들은 모든 튜플이 단 하나의 클래스의 소속된다고 가정한다.
		+ 그러나 각 튜플이 하나 이상의 클래스에 속하는 경우도 있을 수 있음.
		+ 이 경우, 클래스에 속할 확률을 반환하는 것이 좋다.
		+ 이차 추정 휴리스틱(가장 가능성이 높은 1번째, 2번째 클레스에 속하면 옳다고 인정)으로 정확성을 추정 가능.

	![Confusion matrix](https://github.com/jsj267/Data-Mining/blob/master/picture/precision_recall2.png?raw=true)

	1) 정확성 Accuracy(= 인식률 Recognition rate)
		- (TP + TN)/(P + N)
	2) 에러율 Misclassification rate (=오차율)
		- 1 - accuracy(M) (단, accuracy(M) = 분류자 M의 정확성)
		- (FP + FN) / (P + N)
		- 분류모델의 에러율을 측정할 때 테스트 세트로 측정하지만, 훈련 세트로 에러율을 측정하면 최소 에러율, 즉 재대입 오류율(Resubstitution error) 측정 가능.
	3) 민감성 Sensitivity (= 참 긍정 인식률 True positive recognition rate)
		- 긍정 튜플을 얼마나 정확히 인식하는가.
		- TP / P
	4) 특이성 Specificity (= 참 부정 인식률 True negative recognition rate)
		- 부정 튜플을 얼마나 정확히 인식하는가.
		- TN / P
		- 정확성 = 민감성 + 특이성
	5) 정밀도 Precision
		- 정확함의 정도. 긍정으로 예측한 튜플이 실제로 참인 비율
		- TP / (TP+FP)
	6) 재현율 Recall
		- 완결성의 정도. 참인 튜플 중에 긍정으로 예측한 비율
		- TP / (TP+FN) = TP / P = sensitivity
		- Precision과 Recall은 서로 역의 관계. precision은 모델의 입장에서 TP를 바라보고, recall은 실제 정답의 입장에서 TP를 바라봄.
		- 클래스 불균형 상태에서 precision은 높으나 recall은 낮을수 있다. precision과 recall은 trade-off 관계에 있지만 두 수치가 높은 모델일수록 좋은 모델.
	![Precision and Recall](https://github.com/jsj267/Data-Mining/blob/master/picture/precision_recall.png?raw=true)
	7) F측정법(= F1 score)
		- Precision과 Recall의 조화 평균
		- 조화평균은 기하학적으로 A>B일 때, 더 작은 B에 치우치며 B보다 작은 값.
		- 2 * precision * recall / (precision + recall)
	8) Fbeta 측정법
		- precision과 recall의 가중치합
		- (1+beta^2) * precision * recall / (beta^2 * precision + recall) (단, beta는 상수)

2. 홀드아웃 메소드 / 무작위 서브 샘플링
	1) 홀드아웃 메소드
		- 주어진 데이터를 무작위로 나누어 훈련 세트 / 테스트 세트를 구성.
		- 일반적으로 2/3를 훈련 세트로 모델을 구성하는 데 사용하고, 1/3을 테스트 세트로 모델의 정확성을 추정한다
	2) 무작위 서브 샘플링
		- 홀드아웃 기법을 k번 연속으로 적용하는 방법
		- k번 반복으로 측정한 정확성의 평균을 구하여 정확성으로 추정한다.

3. 교차검증, k다면 교차 검증(k-fold cross-validation)
	- 초기 데이터를 무작위로 비슷한 크기의 k개의 상호 독립적인 하위집합(fold)으로 나누어 측정하는 방법
	- i번 측정에서 Di를 테스트 세트로 삼는다면 나머지 k-1세트를 훈련 세트로 사용. (i=1,2,...,k)
	- k개의 하위 집합을 바탕으로 k번 정확성을 반복 측정한다.
	- 정확성 = (k 반복 실행에서 정확하게 분류한 튜플의 개수 합) / (k * 초기 데이터 전체의 크기)
	+ 이 외 하나빼기(leave-one-out) : 한번에 단 하나의 세트만 테스트 세트로 빼고 나머지 전체를 훈련세트로
	+ 이 외 점층 교차 검증(stratified cross-validation) : 각 세트마다 초기 데이터와 거의 비슷한 클래스 분포가 되도록 모든 세트를 층으로 나누어 구성.

4. 부트스트랩(bootstrap)
	- 훈련 튜플을 같은 확률의 독립시행으로 샘플링하여 구성한다. 즉, 한 튜플이 훈련 세트에 추가될 수 있음.
	- 이 때문에 과적합 경향이 있어 비교적 작은 데이터 세트에서 잘 작동한다고 한다.(과적합 경향이 있는데 왜 작은 데이터 세트에서 잘 작동할까?)
	- .632기법
		+ d개의 튜플을 포함하는 데이터 세트에서 d크기의 훈련 세트 샘플인 부트스트랩 샘플을 구성
		+ 선택되지 않은 튜플을 테스트 세트로 구성.
		+ 확률 상으로 63.2%가 훈련 세트로, 36.8%가 테스트 세트로 구성된다.

5. 통계적 유의성을 이용한 모델 선택
	- 두 모델 M1, M2 중 어떤 모델을 선택할지에 대해, 10 fold cross validation 평균 에러율을 비교하여 낮은 에러율을 갖는 모델을 선택하는 것이 이상적이다.
	- 그러나 평균 에러율의 차이가 적다면 또는 에러율이 비슷해서 매번 크고 작음이 바뀐다면?
	- 두 모델 사이에 진정한 차이가 있는지 '통계적 유의성'을 테스트하자.
	- 귀무가설 H0 : M1, M2 모델이 같다, 즉, 두 모델에서 각각 측정한 평균 에러율의 오차는 0에 수렴한다.
	- H0를 기각할 수 있다면 두 모델 사이에 통계적으로 유의미한 차이가 있다는 결론. 기각할만한 충분한 증거가 있다면 에러율이 낮은 모델을 선택하면 된다.
	- 10 fold cross validation일 때, 10개의 에러율이 생기는데. 이 에러율 각각은 확률분포를 따르는 독립사건이므로
	- 에러율은 자유도가 k-1인 t분포를 따른다. (10 fold이므로 k=10)
	- 따라서 t 테스트 유의성 검증.
	- 테스트 세트를 하나로 채용할 경우, 즉 두 모델에 같은 테스트 세트를 적용할 경우
		+ 매 fold 마다 두 모델을 대칭비교(pairwise comparison)한다.
		+ t = ( avg(err(M1)) - avg(err(M2)) / var(M1-M2)
		+ 단, avg(err(M)) : 모델 M의 평균 에러율, var(M1-M2) : 두 모델의 오차율의 편차
	- 테스트 세트를 2개로 채용할 경우, 이항 t테스트. 모델의 분산이 다르므로 var(M1-M2), 두 모델의 오차율의 편차를 다르게 계산.

6. 비용효율과 ROC곡선을 이용한 모델 선택 (클래스 불균등과 연결해서 생각하기)
	- 분류에 따라 비용(또는 위험성)과 이득(효과, 소득)이 상이하다면 결정에 따르는 비용(이득)을 평균값으로 적용하는 대신 각각의 결정에 서로 다른 가중치를 둘 수 있다.
		- ex) 비용 효율 분석 cost-benefit analysis.
			+ 대출 신청 평가의 경우, 파산 위험도 : 일반 신용자의 대출 거부 > 신용 불량자의 대출 승인
			+ 메일 발송의 경우, 부담 : 반응이 없는 가구 우편 비용 > 반응가능성 있는 가구에 자료를 보내지 않는 비용
	- ROC 곡선(Receiver Operating Characteristeic Curve)
		+ 2가지 분류 모델을 비교하는데 유용한 비주얼 도구
		![ROC curve](https://github.com/jsj267/Data-Mining/blob/master/picture/ROC-curve.png?raw=true)
			+ TPR(True Positive Rate) = TP / P = 민감성
			+ FPR(False Positive Rate) = FP / N = 1- 특이성
			+ 각각 민감성과 특이성에 관한 지표이므로 클래스 불균등이 존재해도 이를 반영할 수 있다.
		+ ROC 곡선 그리기
			* 각 튜플의 예상 클래스 확률 분포 정보를 바탕으로(=모델 예측값) 튜플을 긍정(Positive)확률을 기준으로 내림차순 정렬한다.
			* 정렬한 튜플 목록을 바탕으로 실제 라벨과 비교해서 실제 긍정이면 TP(TPR증가), 실제 부정이면 FP(FPR 증가)
			* 해당 점을 그래프에 그린다.
		* ROC 곡선 해석
			* 검정 대각선은 무작위로 라벨을 분류하는 모델.
			* 곡선이 TPR 축에 가까울수록 모델 정확성이 높다. 따라서 빨간색 모델보다 파란색 모델이 더 좋은 모델.
			* 곡선 아래의 면적이 클수록 이상적인 모델이다. 즉 1.0에 가까울수록 좋은 모델이고, 0.5에 가까우면 거의 무작위로 분류하는 모델. 따라서 파란색 모델이 더 좋은 모델.
			* 긍정 확률을 기준으로 내림차순 정렬하여 차례대로 그래프를 그리기 때문에 초반 튜플들이 TPR 기울기가 가파르다. 뒤로 갈수록 긍정 확률이 낮아지기 때문에 기울기가 작아져 거의 수평을 그리는 편.


#### 8.6 분류정확성 향상 기법
1. 앙상블 개론
	- 앙상블 기법 Ensemble method : 다양한 분류자를 조합해서 구성한 복합 모델 또는 그 조합 기법.
	- 훈련 데이터 세트 D로 D1,D2,...,Dk를 구성하고, 각 Di로 분류자 Mi를 구성한다.
	- 입력 데이터 튜플에 대해서 각 분류자는 자신의 예상 클래스를 반환하고 복합 분류자가 이를 표결하여 최종 결과 클래스를 반환.
	- ex) 배깅, 부스팅, 랜덤포레스트
	- 앙상블의 정확도는 개별 분류자보다 높은 편. 서로 다른 CPU에서 처리 가능하기 때문에 병렬 처리에 적합.

2. 배깅 Bagging
	- 각 분류자가 예상 클래스를 반환하면 배깅은 모든 분류자에 동등한 가중치를 두고 다수결에 의해 결과 클래스를 결정한다.
	- y가 연속적 속성값이라면 '평균값'을 반환.
	- 훈련데이터 D에서 반복독립시행(Bootstrap)을 통해 각 Di를 구성한다.
	- 그래서 Bagging = Bootstrap aggregation

3. 부스팅Boosting과 AdaBoost
	- 부스팅은 배깅과 달리 분류자와 튜플에 가중치를 둔다.
	- 배깅은 개별 분류기와 분류기 사이에 독립적인데, 부스팅은 하나의 분류기 후에 그 분류기에서 얻은 정보를 바탕으로 다른 분류기를 만들기 때문에 서로 영향받는다.
	- 개별 분류기를 weak learner, 합한 분류기를 strong learner
	- 가장 유명한 부스팅 알고리즘은 AdaBoost(Adaptive Boosting)
		+ 잘못 분류한 튜플에 가중치를 높이고, 정확하게 분류한 튜플의 가중치를 줄여 분류가 어려웠던 튜플을 더 신경써서 분류하는 알고리즘
		+ 부트스트랩 방식으로 샘플링하여 구성한 데이터 튜플 Di로 모델 Mi를 학습시킨다.
		+ 모델의 오차율 error(Mi) = 각 튜플의 가중치 * 튜플 Xj의 오차(잘못 분류하면 1, 정확하게 분류하면 0)의 총합으로 구한다. 단 error(Mi) > 0.5 이면 모델 파기.
		+ 모델의 오차율을 이용하여 튜플의 가중치를 조절한다.
		+ 정확하게 분류한 튜플에 error(Mi) / (1-error(Mi))를 곱한 후, 모든 튜플의 가중치 합이 같도록 가중치를 평준화한다.
		+ error(Mi) < 0.5 이므로 error(Mi) / (1-error(Mi))는 1보다 작다. 따라서 정확하게 분류한 튜플의 가중치 값은 작아지고, 잘못 분류한 튜플의 가중치는 가중치 평준화로 인해 커진다.
		+ 입력한 튜플에 대한 예상 클래스에 모델의 오차율을 이용한 가중치( Wi = log((1-error(Mi)) / error(Mi)) )를 곱하여 최종 결과 클래스 라벨을 반환한다.
		+![AdaBoost](https://github.com/jsj267/Data-Mining/blob/master/picture/AdaBoost.jpg?raw=true)
	- 참고한 교재가 15년도 책이기 때문에 다른 부스팅 알고리즘을 살펴봤다.
		+ Gradient Boosting
			* Gradient를 이용하여 이전 모델의 오차를 줄여가며 Boosting하는 알고리즘
			* 머신러닝 알고리즘 중에서도 예측 성능이 뛰어나다고.
			* XGBoost가 대표적인 라이브러리. Kaggle에서 핫하다.
	- 그래서 배깅과 비교했을 때, 과적합 가능성이 높지만 정확성은 보통 단일 분류자 < 배깅 < 부스팅 순.

4. 랜덤 포레스트 Random forest
	- 앙상블 구성 기반 분류자가 Decision Tree. 여러개의 의사결정나무의 다수결로 결과 클래스를 결정한다.
	- Decision Tree에 랜덤성을 부여하는데
		+ 데이터를 부트스트랩하여 각 나무를 구성한다.
		+ 파티션을 나누는 변수에 랜덤성을 부여한다. 남아있는 모든 변수 중 최적의 변수를 선택하는 것이 아니라 변수 중 일부에서 최적의 변수를 선택한다.
	- 정확성이 높고. 오차와 이상치에 대해 견고함. 또한 과적합 문제도 해결할 수 있어 인기있는 알고리즘

5. 불균형 클래스 데이터의 정확성 향상
	- 알고자 하는 클래스(긍정 클래스)가 희소하게 등장하고 대부분의 튜플이 부정 클래스에 속하는 경우.
	- 비용 최적화 학습 문제.
	- 앞에서 민감성과 특이성, F1, Fbeta 측정기준, ROC곡선 등을 통해 평가할 수 있음.
	- 이뿐만 아니라
		+ 과대(over sampling)/과소 샘플링(under sampling) : 희박했던 긍정클래스가 부정 클래스와 같은 비율이 되도록 훈련 세트의 튜플 분포를 달리하는 것. 과대 샘플링은 긍정 튜플을 반복 추출하고, 과소 샘플링은 부정 튜플의 샘플 숫자를 줄여 두 클래스가 같은 비율로 등장하도록 한다. over/under sampling엔 다양한 방법이 있는데, [참고](https://datascienceschool.net/view-notebook/c1a8dad913f74811ae8eef5d3bedc0c3/). 그런데 오버샘플링의 보다 under sampling과 training set에 가중치를 주는 방식이 더 좋은 결과를 보여준다고 주장하는 연구들이 [많다고 한다.](http://freesearch.pe.kr/archives/4506)
		+ 역치 이동 : 출력 결과를 바탕으로 분류 결정을 조정하는 것. 입력 튜플에 대해 연속 출력값을 반환하는(ex sigmoid) 분류자에 적용 가능. 나이브 베이지안/ 신경망 분류자와 같은 분류자. ex) f(X)>=t 이면 긍정 튜플로, f(X)<t이면 부정 튜플로.
		+ 앙상블 기법

참고 :
- 밑바닥부터 시작하는 데이터과학
- https://3months.tistory.com/368
- https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting
