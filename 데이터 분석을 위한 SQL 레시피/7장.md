#### 데이터 활용의 정밀도를 높이는 분석 기술
1. 데이터를 조합해서 새로운 데이터 만들기
	- 외부 데이터를 읽어 들이는 방법과 데이터를 가공하는 방법
	
	1) IP 주소를 기반으로 국가와 지역 보완하기
		- IP 주소가 있다면 국가와 지역을 알 수 있다. 
		- 타임존을 구분하여 분석 가능.
		
		```sql
		DROP TABLE IF EXISTS mst_city_ip;
		CREATE TABLE mst_city_ip (
			network 							inet PRIMARY KEY
			, geoname_id						integer
			, registered_country_geoname_id 	integer
			, represented_country_geoname_id 	integer
			, is_anonymous_proxy				boolean
			, is_stellite_provider				boolean
			, postal_code						varchar(255)
			, latitude 							numeric
			, longitude							numeric
			, accuracy_radius					integer
		);

		DROP TABLE IF EXISTS mst_locations;
		CREATE TABLE mst_locations(
			geoname_id					integer PRIMARY KEY
			, locale_code				varchar(255)
			, continent_code			varchar(10)
			, continent_name 			varchar(255)
			, country_iso_code 			varchar(10)
			, country_name				varchar(255)
			, subdivision_1_iso_code 	varchar(10)
			, subdivision_1_name		varchar(255)
			, subdivision_2_iso_code	varchar(10)
			, subdivision_2_name		varchar(255)
			, city_name 				varchar(255)
			, metro_code				integer
			, time_zone					varchar(255)
			, is_in_european_union 		boolean
		);

		-- 서버 위치는 윈도우 기준 C:\Program Files\PostgreSQL\10\data
		COPY mst_city_ip FROM './GeoLite2-City-Blocks-IPv4.csv' WITH CSV HEADER;
		COPY mst_locations FROM './GeoLite2-City-Locations-en.csv' WITH CSV HEADER;		
		
		SELECT 
			a.ip
			, l.continent_name
			, l.country_name
			, l.city_name
			, l.time_zone
		FROM
			action_log_with_ip AS a
			LEFT JOIN
			mst_city_ip AS i 
			ON a.ip::inet << i.network
			LEFT JOIN
			mst_locations AS l
			ON i.geoname_id = l.geoname_id
		;
		```
		
	2) 주말과 공휴일 판단하기
		- 보통 서비스는 주말과 공휴일에 방문 횟수와 CV가 증가.
		
		```sql
		SELECT
			a.action
			, a.stamp
			, c.dow
			, c.holiday_name
			, c.dow_num IN (0,6)
				OR c.holiday_name IS NOT NULL
				AS is_day_off
		FROM
			access_log AS a
			JOIN
			-- mst_calendar 테이블은 주말과 공휴일을 정의해놓은 테이블
			mst_calendar AS c
			ON CAST(substring(a.stamp, 1, 4) AS int) = c.year
			AND CAST(substring(a.stamp, 6, 2) AS int) = c.month
			AND CAST(substring(a.stamp, 9, 2) AS int) = c.day
		;
		```
	
	3) 하루 집계 범위 변경하기
		- 보통 자정을 기준으로 하루를 계산하는 것보다 이용자가 가장 적은 시간대(ex 오전 4시)를 기준으로 하루를 계산하는 것이 좋다.
		
		```sql
		-- stamp에서 4시간 전으로 시간을 맞추고 이에 따라 4시간 당긴 날짜로 다시 계산함
		WITH
		action_log_with_mod_stamp AS (
			SELECT *
				, CAST(stamp::timestamp - '4 hours'::interval AS text) AS mod_stamp
			FROM action_log
		)

		SELECT
			session
			, user_id
			, action
			, stamp
			, substring(stamp, 1, 10) AS raw_date
			, substring(mod_stamp, 1, 10) AS mod_date
		FROM action_log_with_mod_stamp
		;		
		```
	
2. 이상값 검출하기	
	1) 데이터 분산 계산하기
		- 이상값을 검출하는 방법 중 가장 기본적인 방법 : 데이터의 분산에서 많이 벗어난 값을 찾기
		- 페이지 조회 수가 극단적으로 높은 경우, 다른 업체 또는 크롤러인 가능성이 있음.
		- 페이지 조회 수가 극단적으로 낮은 경우도 문제가 있을 수 있다.
		
		```sql
		WITH
		session_count AS (
			SELECT
				session
				, COUNT(1) AS count
			FROM action_log_with_noise
			GROUP BY session
		)

		SELECT
			session
			, count
			, RANK() OVER(ORDER BY count DESC) AS rank
			, PERCENT_RANK() OVER(ORDER BY count DESC) AS percent_rank
		FROM session_count
		;		
		```
		
	2) 크롤러 제외하기
		- 사용자 에이전트 등을 보고 크롤러를 구분 가능.
		- 2가지 방법
			+ 규칙을 기반으로 제외하기 : 보통 특정 문자열(bot / creawler / spider 등)을 포함하고 있음
				
				```sql
				SELECT *
				FROM action_log_with_noise
				WHERE
					NOT
					(	user_agent LIKE '%bot%'
					OR user_agent LIKE '%crawler%'
					OR user_agent LIKE '%spider%')
				;			
				```
				
			+ 마스터 데이터를 사용해 제외하기 : 크롤러가 포함하는 특정 문자열 규칙을 크롤러 마스터 데이터로 만들어 제외.
				```sql
				WITH
				mst_bot_user_agent AS (
						SELECT '%bot%' AS rule
					UNION ALL SELECT '%crawler%' AS rule
					UNION ALL SELECT '%spider%' AS rule
					UNION ALL SELECT '%archiver%' AS rule
				)
				, filtered_action_log AS (
					SELECT
						l.stamp, l.session, l.action, l.products, l.url, l.ip, l.user_agent
					FROM action_log_with_noise AS l
					-- 상관 서브쿼리
					WHERE
						NOT EXISTS (
							SELECT 1
							FROM mst_bot_user_agent AS m
							WHERE l.user_agent LIKE m.rule
						)
				)

				SELECT *
				FROM filtered_action_log
				;				
				```
	
	3) 데이터 타당성 확인하기
		- 데이터의 결손이나 오류 검사.
		
		```sql
		SELECT 
			action
			-- 항목 입력이 필수일 경우 1, 입력이 되지 않아야하는 경우 0.
			-- avg 함수를 사용해서 값이 입력되거나 입력되지 않았을 경우 타당성을 체크함.
			, AVG(CASE WHEN session IS NOT NULL THEN 1.0 ELSE 0.0 END) AS session
			, AVG(CASE WHEN user_id IS NOT NULL THEN 1.0 ELSE 0.0 END) AS user_id
			, AVG(CASE action
					WHEN 'view' THEN 
						CASE WHEN category IS NULL THEN 1.0 ELSE 0.0 END
					ELSE
						CASE WHEN category IS NOT NULL THEN 1.0 ELSE 0.0 END
				 END
				 )AS category
			, AVG(CASE action
					WHEN 'view' THEN
						CASE WHEN products IS NULL THEN 1.0 ELSE 0.0 END
					ELSE 
						CASE WHEN products IS NOT NULL THEN 1.0 ELSE 0.0 END
				 END
				 ) AS products
			, AVG(CASE action
					WHEN 'purchase' THEN
						CASE WHEN amount IS NOT NULL THEN 1.0 ELSE 0.0 END
					ELSE
						CASE WHEN amount IS NULL THEN 1.0 ELSE 0.0 END
				 END
				 ) AS amount
			, AVG(CASE WHEN stamp IS NOT NULL THEN 1.0 ELSE 0.0 END) AS stamp
		FROM invalid_action_log
		GROUP BY action
		;
		```
	
	4) 특정 IP 주소에서의 접근 제외하기
		- 정규 서비스 사용자 이외 테스트 사용자, 사내 접근, 크롤러, 부정적인 접근은 제외하고 분석하는 것이 좋다. 
		- inet 자료형은 PostgreSQL에서만 있기 때문에 다른 미들웨어에서는 대소 비교 가능한 형식으로 바꾸어 비교해야함.
		
		```sql
		WITH
		mst_reserved_ip AS (
				SELECT '127.0.0.0/0' AS network, 'localhost' AS description
			UNION ALL SELECT '10.0.0.0/0' AS network, 'Private network' AS description
			UNION ALL SELECT '172.16.0.0/12' AS network, 'Private network' AS description
			UNION ALL SELECT '192.0.0.0/24' AS network, 'Private network' AS description
			UNION ALL SELECT '192.168.0.0/16' AS network, 'Private network' AS description
		)
		, action_log_with_reserved_ip AS (
			SELECT
				l.user_id
				, l.ip
				, l.stamp
				, m.network
				, m.description
			FROM 
				action_log_with_ip AS l
				LEFT JOIN
				mst_reserved_ip AS m
				ON l.ip::inet << m.network::inet
				-- inet 자료형은 IP 주소와 네트워크 범위를 다룰 때 사용. 
				-- IP주소가 제외할 ip 마스터 테이블의 network에 포함되었는지 판정하기 위해 << 사용.
		)

		SELECT *
		FROM action_log_with_reserved_ip
		;		
		```
	
3. 데이터 중복 검출하기
	- RDB의 경우 유니크 키를 설정했을 경우, 키가 중복되면 자동으로 오류가 발생하여 데이터의 무결성이 보장됨.
	- 그러나 Hive, BigQuery와 같은 RDB가 아닌 데이터베이스에서는 데이터 중복을 사전에 확인하는 기능이 없음.
	- *[다른 데이터베이스 살펴보기](https://github.com/jsj267/Concept-and-Theory/blob/master/Hive.md)*
	
	1) 마스터 데이터의 중복 검출하기
		- 마스터 데이터에 중복이 존재할 경우, 로그 데이터와 결합하면 잘못된 분석 결과를 만들 수 있음. 
		- 마스터 데이터에 중복이 발생하는 원인
			+ 데이터를 로드할 때 실수로 여러번 로드되어 레코드가 중복 생성됨.
			+ 값을 갱신할 때 문제가 생겨, 오래된 데이터와 새로운 데이터가 서로 다른 레코드로 분리됨.
			+ 운용상의 실수로 같은 ID를 다른 데이터에 재사용한 경우.
		
		```sql
		-- id 개수를 기준으로 중복이 있는지 확인하기
		SELECT
			COUNT(1) AS total_num
			, COUNT(DISTINCT id) AS key_num	
		FROM mst_categories
		;		
		```
		
		```sql
		-- 중복인 레코드 확인하기
		WITH
		mst_categories_with_key_num AS (
			SELECT *
				, COUNT(*) OVER(PARTITION BY id) AS key_num
			FROM mst_categories
		)

		SELECT *
		FROM mst_categories_with_key_num
		WHERE key_num > 1
		;
		```
		
	2) 로그 중복 검출하기 
		- 사용자가 2번 클릭하거나, 페이지의 새로고침으로 인해 로그가 2회 동시에 발생하는 경우 등으로 인해 로그 중복 발생.
		- 로그 중복은 완전히 같은 레코드가 아닌 일부(사용자, action 등)가 같고 타임스탬프가 얼마 차이나지 않는 로그를 중복으로 처리할 수도 있다.
		
		```sql
		-- 중복 로그 데이터 확인
		SELECT
			user_id
			, products
			, string_agg(session, ',') AS session_list
			, string_agg(stamp, ',') AS stamp_list
		FROM dup_action_log
		GROUP BY user_id, products
		HAVING COUNT(*) > 1
		;
		```
		
		```sql
		-- 중복 데이터 제외하기
		SELECT
			session
			, user_id
			, action
			, products
			, MIN(stamp) AS stamp
			-- 이 경우 stamp를 집약함수로 해서 중복을 없앴지만 다른 속성의 경우 집약함수를 사용할 수 없으면 행에 순번을 부여해야함.
		FROM dup_action_log
		GROUP BY session, user_id, action, products
		;		
		```
		
		```sql
		-- 행에 순번 부여
		WITH
		dup_action_log_with_order_num AS (
			SELECT *
				, ROW_NUMBER() 
					OVER(PARTITION BY session, user_id, action, products ORDER BY stamp)
					AS order_num
			FROM dup_action_log
		)

		SELECT
			session
			, user_id
			, action
			, products
			, stamp
		FROM dup_action_log_with_order_num
		WHERE order_num = 1
		;
		```
		
		```sql
		-- stamp 차이가 작으면 중복 판정하기
		WITH
		dup_action_log_with_lag_seconds AS (
			SELECT
				user_id
				, action
				, products
				, stamp
				, EXTRACT(epoch from stamp::timestamp - LAG(stamp::timestamp)
						 OVER(PARTITION BY user_id, action, products ORDER BY stamp
					)) AS lag_seconds
			FROM dup_action_log
		)

		SELECT 
			user_id
			, action
			, products
			, stamp
		FROM dup_action_log_with_lag_seconds
		WHERE (lag_seconds IS NULL OR lag_seconds >= 30*60)
		ORDER BY stamp
		;		
		```

4. 여러 개의 데이터셋 비교하기
	1) 데이터의 차이 추출하기
		- 마스터 데이터는 시점에 따라 그 내용이 변경된다. 
		- 다른 시점의 마스터 데이터 간의 차이를 보고 싶을 때. 
		
		```sql
		-- 새로 추가된 상품들만 추리기
		-- 오래되어 제거된 상품들을 보려면 RIGHT OUTER JOIN
		SELECT
			new_mst.*
		FROM
			mst_products_20170101 AS new_mst
			LEFT OUTER JOIN
			mst_products_20161201 AS old_mst
			ON new_mst.product_id = old_mst.product_id
		WHERE old_mst.product_id IS NULL
		;		
		```
		
		```sql
		-- 갱신된 마스터 데이터 추출하기
		SELECT
			new_mst.product_id
			, old_mst.name AS old_name
			, old_mst.price AS old_price
			, new_mst.name AS new_name
			, new_mst.price AS new_price
			, old_mst.updated_at AS old_updated_at
			, new_mst.updated_at AS new_updated_at
		FROM
			mst_products_20170101 AS new_mst
			JOIN
			mst_products_20161201 AS old_mst
			ON new_mst.product_id = old_mst.product_id
		WHERE
			new_mst.updated_at <> old_mst.updated_at
		;
		```
		
		```sql
		-- 변경된 마스터 데이터를 모두 추출
		SELECT
			COALESCE(new_mst.product_id, old_mst.product_id) AS product_id
			, COALESCE(new_mst.name, old_mst.name) AS name
			, COALESCE(new_mst.price, old_mst.price) AS price
			, COALESCE(new_mst.updated_at, old_mst.updated_at) AS updated_at
			, CASE
				WHEN old_mst.updated_at IS NULL THEN 'added' 
				WHEN new_mst.updated_at IS NULL THEN 'deleted'
				WHEN new_mst.updated_at <> old_mst.updated_at THEN 'updated'
				END AS status
		FROM
			mst_products_20170101 AS new_mst
			FULL OUTER JOIN
			mst_products_20161201 AS old_mst
			ON new_mst.product_id = old_mst.product_id
		WHERE new_mst.updated_at IS DISTINCT FROM old_mst.updated_at
		-- IS DISTINCT FROM = <> (NULL 포함)
		;
		```
		
	2) 두 순위의 유사도 계산하기
		- 하나의 지표만으로 판단하기 어려울 때, 여러개의 지표의 순위를 비교해보고자 할 때.
		
		```sql
		WITH
		path_stat AS (
			SELECT
				path
				, COUNT(DISTINCT long_session) AS access_users
				, COUNT(DISTINCT short_session) AS access_count
				, COUNT(*) AS page_view
			FROM access_log
			GROUP BY path
		)
		, path_ranking AS (
			-- 방문자 수 / 방문 횟수 / 페이지 뷰 를 기준으로 각 순위 구하기
			SELECT 'access_user' AS type, path, RANK() OVER(ORDER BY access_users DESC) AS rank FROM path_stat
			UNION ALL 
			SELECT 'access_count' AS type, path, RANK() OVER(ORDER BY access_count DESC) AS rank FROM path_stat
			UNION ALL
			SELECT 'path_view' AS type, path, RANK() OVER(ORDER BY page_view DESC) AS rank FROM path_stat
		)
		, pair_ranking AS (
			SELECT
				r1.path
				, r1.type AS type1
				, r1.rank AS rank1
				, r2.type AS type2
				, r2.rank AS rank2
				, POWER(r1.rank - r2.rank, 2) AS diff
			FROM
				path_ranking AS r1
				JOIN
				path_ranking AS r2
				ON r1.path = r2.path
		)
		SELECT 
			type1, type2
			-- 스피어만 상관계수로 순위의 유사도를 계산
			-- 두 개의 순위가 완전히 일치하면 1, 완전히 일치하지 않을 경우 -1. 
			-- 1에 가까운 양의 값을 가질수록 두 순위가 연관성을 가지고, -1에 가까운 음의 값을 가질수록 연관성이 없다는 것을 의미
			, 1 - ( 6.0 * SUM(diff) / (POWER(COUNT(1), 3) - COUNT(1))) AS spearman
		FROM pair_ranking
		GROUP BY type1, type2
		ORDER BY type1, spearman DESC
		;		
		```
