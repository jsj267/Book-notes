### 데이터를 무기로 삼기 위한 분석 기술

1. 검색 기능 평가하기
	- 서비스에서 내부 검색 기능을 제공하는 경우, 검색 기능을 평가 및 개선하기 위해 
	- 검색하는 사용자의 행동
		+ 검색했을 때 원하는 검색 결과가 나오면, 상세 화면으로 이동(Hit) 
		+ 검색했을 때 원하는 검색 결과가 나오지 않으면, 재검색(필터링, 다른 어구) 또는 이탈
	- 검색 기능 개선 방법
		+ 동의어 사전 추가하기 : 검색 키워드의 흔들림을 흡수할 수 있도록
		+ 사용자 사전 추가하기 : 검색 엔진이 검색 키워드를 이해할 수 있도록
		+ 정렬 순서 조정하기 : 사용자가 원하는 순서대로 검색 결과가 나올 수 있도록
	
	1) NoMatch 비율과 키워드 집계하기
		- NoMatch 비율 = 검색 결과가 0인 수 / 검색 총 수 
		
		```sql
		-- NoMatch 비율 구하기
		SELECT 
			substring(stamp, 1, 10) AS dt
			, COUNT(1) AS search_count
			, SUM(CASE WHEN result_num = 0 THEN 1 ELSE 0 END) AS no_match_count
			, AVG(CASE WHEN result_num = 0 THEN 1.0 ELSE 0.0 END) AS no_match_rate
		FROM access_log
		WHERE action = 'search'
		GROUP BY dt
		;		
		```
		
		```sql
		WITH
		search_keyword_stat AS (
			SELECT 
				keyword
				, result_num
				, COUNT(1) AS search_count
				, 100.0 * COUNT(1) / COUNT(1) OVER() AS search_share
			FROM access_log
			WHERE action = 'search'
			GROUP BY keyword, result_num
		)

		SELECT 
			keyword
			, search_count
			, search_share
			, 100.0 * search_count / SUM(search_count) OVER() AS no_match_share
		FROM search_keyword_stat
		WHERE result_num=0		
		;
		```
		
	2) 재검색 비율과 키워드 집계하기
		- 재검색 비율이 얼마나 되는지
		
		```sql
		WITH
		access_log_with_next_action AS (
			SELECT 
				stamp::text
				, session
				, action
				, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
			FROM access_log
		)

		SELECT
			substring(stamp, 1, 10) AS dt
			, COUNT(1) AS search_count
			, SUM(CASE WHEN next_action='search' THEN 1 ELSE 0 END) AS retry_count
			, AVG(CASE WHEN next_action='search' THEN 1.0 ELSE 0.0 END) AS retry_rate
		FROM access_log_with_next_action
		WHERE action = 'search'
		GROUP BY dt
		ORDER BY dt
		;		
		```
		
		- 재검색 키워드를 알면 키워드를 비교해서 검색 기능을 어떻게 수정할지 고민할 수 있음.
		
		```sql
		WITH
		access_log_with_next_search AS (
			SELECT
				stamp
				, session
				, action
				, keyword
				, result_num
				, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
				, LEAD(keyword) OVER(PARTITION BY session ORDER BY stamp) AS next_keyword
				, LEAD(result_num) OVER(PARTITION BY session ORDER BY stamp) AS next_result_num
			FROM access_log
		)

		SELECT 
			keyword
			, result_num
			, COUNT(1) AS retry_count
			, next_keyword
			, next_result_num
		FROM access_log_with_next_search
		WHERE action='search' AND next_action='search'
		GROUP BY keyword, result_num, next_keyword, next_result_num
		;
		```
		
	3) 재검색 키워드를 분류해서 집계하기
		- 재검색 유형
			+ 검색 결과가 0개이므로(NoMatch) 다른 검색어로 검색
			
			```sql
			-- NoMatch상태에서 다시 검색했다면 동의어일 가능성이 높음.
			-- 재 검색어는 동의어 사전이나 사용자 사전에 추가할 키워드 후보.
			WITH
			access_log_with_next_search AS (
				SELECT
					stamp
					, session
					, action
					, keyword
					, result_num
					, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
					, LEAD(keyword) OVER(PARTITION BY session ORDER BY stamp) AS next_keyword
					, LEAD(result_num) OVER(PARTITION BY session ORDER BY stamp) AS next_result_num
				FROM access_log
			)

			SELECT
				keyword
				, result_num
				, COUNT(1) AS retry_count
				, next_keyword
				, next_result_num
			FROM access_log_with_next_search
			WHERE action='search' AND next_action='search'
					AND result_num=0
			GROUP BY keyword, result_num, next_keyword, next_result_num
			;			
			```
			
			+ 검색 결과가 많아 단어를 필터링하여 검색
			
			```sql
			WITH
			access_log_with_next_search AS (
				SELECT
					stamp
					, session
					, action
					, keyword
					, result_num
					, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
					, LEAD(keyword) OVER(PARTITION BY session ORDER BY stamp) AS next_keyword
					, LEAD(result_num) OVER(PARTITION BY session ORDER BY stamp) AS next_result_num
				FROM access_log
			)

			SELECT
				keyword
				, result_num
				, COUNT(1) AS retry_count
				, next_keyword
				, next_result_num
			FROM access_log_with_next_search
			WHERE action='search' AND next_action='search'
					AND next_keyword LIKE concat('%', keyword, '%')
			GROUP BY keyword, result_num, next_keyword, next_result_num
			;			
			```
			
			+ 검색 결과가 나오기는 했지만 다른 검색어로 변경하여 검색
			
			```sql
			WITH
			access_log_with_next_search AS (
				SELECT
					stamp
					, session
					, action
					, keyword
					, result_num
					, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
					, LEAD(keyword) OVER(PARTITION BY session ORDER BY stamp) AS next_keyword
					, LEAD(result_num) OVER(PARTITION BY session ORDER BY stamp) AS next_result_num
				FROM access_log
			)

			SELECT
				keyword
				, result_num
				, COUNT(1) AS retry_count
				, next_keyword
				, next_result_num
			FROM access_log_with_next_search
			WHERE action='search' AND next_action='search'
					AND next_keyword NOT LIKE concat('%', keyword, '%')
			GROUP BY keyword, result_num, next_keyword, next_result_num
			;
			```
			
	4) 검색 이탈 비율과 키워드 집계하기
		- next action이 없다면 검색 결과에 만족하지 못해 이탈한 사용자.
		
		```sql
		-- 검색 이탈율
		WITH
		access_log_with_next_action AS (
			SELECT 
				stamp::text
				, session
				, action
				, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
			FROM access_log
		)

		SELECT
			substring(stamp, 1, 10) AS dt
			, COUNT(1) AS search_count
			, SUM(CASE WHEN next_action IS NULL THEN 1 ELSE 0 END) AS exit_count
			, AVG(CASE WHEN next_action IS NULL THEN 1.0 ELSE 0.0 END) AS exit_rate
		FROM access_log_with_next_action
		WHERE action = 'search'
		GROUP BY dt
		ORDER BY dt
		;
		```
		
		```sql
		-- 이탈 키워드
		WITH
		access_log_with_next_search AS (
			SELECT
				stamp
				, session
				, action
				, keyword
				, result_num
				, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
				, LEAD(keyword) OVER(PARTITION BY session ORDER BY stamp) AS next_keyword
				, LEAD(result_num) OVER(PARTITION BY session ORDER BY stamp) AS next_result_num
			FROM access_log
		)

		SELECT
			keyword
			, COUNT(1) AS search_count
			, SUM(CASE WHEN next_action IS NULL THEN 1 ELSE 0 END) AS exit_count
			, AVG(CASE WHEN next_action IS NULL THEN 1.0 ELSE 0 END) AS exit_rate
			, result_num
		FROM access_log_with_next_search
		WHERE action='search'
		GROUP BY keyword, result_num
		HAVING SUM(CASE WHEN next_action IS NULL THEN 1 ELSE 0 END) > 0
		;		
		```
		
	5) 검색 키워드 관련 지표의 집계 효율화하기
		
		```sql
		-- 한꺼번에 보기
		WITH
		access_log_with_next_search AS (
			SELECT
				stamp
				, session
				, action
				, keyword
				, result_num
				, LEAD(action) OVER(PARTITION BY session ORDER BY stamp) AS next_action
				, LEAD(keyword) OVER(PARTITION BY session ORDER BY stamp) AS next_keyword
				, LEAD(result_num) OVER(PARTITION BY session ORDER BY stamp) AS next_result_num
			FROM access_log
		)
		, search_log_with_next_action AS (
			SELECT *
			FROM access_log_with_next_search
			WHERE action='search' AND next_action='search'
		)

		SELECT *
		FROM search_log_with_next_action
		ORDER BY session, stamp
		;		
		```
		
	6) 검색 결과의 포괄성을 지표화하기 -> 재현율
		- 재현율(Recall)
			+ 검색 엔진을 평가하는 지표 
			+ 검색 결과에서 미리 준비한 정답 아이템이 '얼마나' 나왔는가
			+ 특정 키워드로 검색했을 때, 10개의 검색 결과가 나왔으면 했는데 4개의 검색 결과가 나왔다면 재현율은 40%

		```SQL
		WITH
		search_result_with_correct_items AS (
			SELECT
				COALESCE(r.keyword, c.keyword) AS keyword
				, r.rank
				, COALESCE(r.item, c.item) AS item
				, CASE WHEN c.item IS NOT NULL THEN 1 ELSE 0 END AS correct
			FROM
				search_result AS r
				FULL OUTER JOIN
				correct_result AS c
				ON r.keyword = c.keyword 
				-- 아래 조건 넣지 않으면 중복 레코드 발생
				AND r.item = c.item
		)
		, search_result_with_recall AS (
			SELECT
				*
				, SUM(correct) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
								   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cum_correct
				, CASE
					WHEN rank IS NULL THEN 0.0
					ELSE 100.0 * SUM(correct) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
												  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
								/ SUM(correct) OVER(PARTITION BY keyword)
					END AS recall
			FROM search_result_with_correct_items
		)

		SELECT *
		FROM search_result_with_recall
		ORDER BY keyword, rank
		;		
		```
	
		- 여러 검색 엔진을 평가하기 위해 모든 레코드에 대한 재현율보다 집약해서 보기
		
		```SQL
		WITH
		search_result_with_correct_items AS (
			SELECT
				COALESCE(r.keyword, c.keyword) AS keyword
				, r.rank
				, COALESCE(r.item, c.item) AS item
				, CASE WHEN c.item IS NOT NULL THEN 1 ELSE 0 END AS correct
			FROM
				search_result AS r
				FULL OUTER JOIN
				correct_result AS c
				ON r.keyword = c.keyword 
				-- 아래 조건 넣지 않으면 중복 레코드 발생
				AND r.item = c.item
		)
		, search_result_with_recall AS (
			SELECT
				*
				, SUM(correct) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
								   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cum_correct
				, CASE
					WHEN rank IS NULL THEN 0.0
					ELSE 100.0 * SUM(correct) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
												  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
								/ SUM(correct) OVER(PARTITION BY keyword)
					END AS recall
			FROM search_result_with_correct_items
		)
		, recall_over_rank_5 AS (
			SELECT
				keyword
				, rank
				, recall
				, ROW_NUMBER() OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 0) DESC) AS desc_number
			FROM search_result_with_recall
			WHERE COALESCE(rank, 0) <= 5
		)

		SELECT 
			keyword
			, recall AS recall_at_5
		FROM recall_over_rank_5
		WHERE desc_number=1
		; 
		```
		
		```sql
		WITH
		search_result_with_correct_items AS ( SELECT ~ )
		, search_result_with_recall AS ( SELECT ~ )
		, recall_over_rank_5 AS ( SELECT ~ )

		-- 평균내서 모든 키워드에 대한 재현율 집약
		SELECT AVG(recall) AS average_recall_at_5
		FROM recall_over_rank_5
		WHERE desc_number=1
		; 
		```
		
	7) 검색 결과의 타당성을 지표화하기 -> 정확률
		- 정확률(Precision) = P@n 이라고 표기 가능(= 검색 결과 상위 n개의 정확률)
			+ 재현율과 함께 사용되는 검색 결과 평가 지표
			+ 검색 결과에 포함되는 아이템 중 정답 '아이템'이 어느 정도 비율로 포함되는가.
			+ 검색 결과 상위 10개에 5개의 정답 아이템이 포함되어 있다면 정확률은 50%
		- 재현율과 정확률의 차이
			+ 재현율은 '검색 결과' 개수이고, 정확률은 '아이템' 포함 수.
			
		```sql
		WITH
		search_result_with_correct_items AS (
			SELECT
				COALESCE(r.keyword, c.keyword) AS keyword
				, r.rank
				, COALESCE(r.item, c.item) AS item
				, CASE WHEN c.item IS NOT NULL THEN 1 ELSE 0 END AS correct
			FROM
				search_result AS r
				FULL OUTER JOIN
				correct_result AS c
				ON r.keyword = c.keyword AND r.item = c.item
		)
		, search_result_with_precision AS (
			SELECT *
				, SUM(correct)
					OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
						ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cum_correct
				, CASE
					WHEN rank IS NULL THEN 0.0
					ELSE 100.0 * SUM(correct) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
												  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
								-- 재현율과 분모가 다름.
								/ COUNT(1) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
											   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
				END AS precision
			FROM search_result_with_correct_items
		)

		SELECT *
		FROM search_result_with_precision
		ORDER BY keyword, rank
		;		
		```
		
		```sql
		-- 키워드별로 정확률 집계
		WITH
		search_result_with_correct_items AS (
			SELECT
				COALESCE(r.keyword, c.keyword) AS keyword
				, r.rank
				, COALESCE(r.item, c.item) AS item
				, CASE WHEN c.item IS NOT NULL THEN 1 ELSE 0 END AS correct
			FROM
				search_result AS r
				FULL OUTER JOIN
				correct_result AS c
				ON r.keyword = c.keyword AND r.item = c.item
		)
		, search_result_with_precision AS (
			SELECT *
				, SUM(correct)
					OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
						ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cum_correct
				, CASE
					WHEN rank IS NULL THEN 0.0
					ELSE 100.0 * SUM(correct) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
												  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
								-- 재현율과 분모가 다른데, 다시 확인하기.
								/ COUNT(1) OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 100000)
											   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
				END AS precision
			FROM search_result_with_correct_items
		)
		, precision_over_rank_5 AS (
			SELECT
				keyword
				, rank
				, precision
				, ROW_NUMBER() OVER(PARTITION BY keyword ORDER BY COALESCE(rank, 0) DESC) AS desc_number
			FROM search_result_with_precision
			WHERE COALESCE(rank, 0) <= 5
		)
		SELECT 
			keyword
			, precision AS precision_at_5
			-- 검색 엔진 전체의 평균 정확률은
			-- AVG(precision) AS average_precision_at_5
		FROM precision_over_rank_5
		WHERE desc_number=1
		;		
		```
		
	8) 검색 결과 순위와 관련된 지표 계산하기
  		- 재현율과 정확률은 검색 엔진을 평가할 수 있는 기본적인 지표이지만 부족한 점이 있다.
		- 다른 지표들은 502p 참고하기. 이 외 다른 지표들도 많다.
		- 1) 검색 결과의 순위는 고려하지 않는다.
			+ MAP(Mean Average Precision) : 검색 결과 상위 N개의 정확률 평균
			+ MRR(Mean Reciprocal Rank)
		
			```sql
			-- MAP
			WITH
			search_result_with_correct_items AS ( SELECT ~ )
			, search_result_with_precision AS ( SELECT ~ )
			, average_precision_for_keywords AS (
				SELECT 
					keyword
					, AVG(precision) AS average_precision
				FROM search_result_with_precision
				WHERE correct=1
				GROUP BY keyword
			)
			SELECT *
				-- 검색 엔진의 MAP은
				-- AVG(average_precision AS mean_average_precision)
			FROM average_precision_for_keywords
			;			
			```
		
		- 2) 정답과 정답이 아닌 아이템을 0과 1이라는 두 가지 값으로밖에 표현할 수 없다.
			+ 단계적인 점수를 부여하고 싶을 경우.
			+ DCG(Discounted Cumulated Gain)
			+ NDCG(Normalized DCG)
		- 3) 모든 아이템에 대한 정답을 미리 준비하는 것은 현실적으로 어렵다.
			+ 정답 아이템 수가 한정된 경우 BPREF(Binary Preference) 활용 가능.
			
2. 데이터 마이닝
	- 대량의 데이터에서 특정 패턴 또는 규칙 등 유용한 지식을 추출하는 방법을 전반적으로 나타내는 용어.
	- 대부분 재귀 알고리즘과 휴리스틱 알고리즘이 필요하다.
	
	1) 어소시에이션 분석 
		+ 상관 규칙 추출 방법 중 하나
		+ 상품 A를 구매한 사람의 60%는 상품 B도 구매했다.
		+ 동시 시점의 상황이 아니라 시간적 차이가 있는 인과 관계를 의미.
		+ 어소시에이션 분석에 사용되는 주요 지표에는 지지도, 확신도(신뢰도), 리프트가 존재.
		+ 지지도(Support) 
			* 상관 규칙이 어느 정도의 확률로 발생하는가.
			* 100개 구매 로그에서 상품X와 Y를 같이 구매한 로그가 20개면 지지도는 20/100 = 20%
		+ 확신도 또는 신뢰도(Confidence) 
			* 어떤 결과가 어느 정도의 확률로 발생하는가.
			* 100개 구매 로그, 상품 X를 구매한 로그가 50개, 상품 X, Y를 구매한 로그가 20개이면 신뢰도는 20/50 = 40%
		+ 리프트(Lift) 
			* 어떤 조건을 만족하는 경우의 확률 / 사전 조건 없이 해당 결과가 일어날 확률
			* 100개 구매 로그, 상품 X를 구매한 로그가 50개, X,Y를 구매한 로그가 20개, Y를 구매한 로그가 20개일 때
			* 리프트 값은 (20/50) / (20/100) = 2 (확률이 아니다)
			* 해석은 상품 X를 구매한 경우 상품 Y를 구매할 확률이 2배가 된다. 
			* 보통 리프트 값이 1 이상이면 좋은 규칙이라고 판단.
	
		```sql
		WITH
		purchase_id_count AS (
			SELECT COUNT(DISTINCT purchase_id) AS purchase_count
			FROM purchase_detail_log
		)
		, purchase_detail_log_with_counts AS (
			SELECT
				d.purchase_id
				, p.purchase_count
				, d.product_id
				, COUNT(1) OVER(PARTITION BY d.product_id) AS product_count
			FROM 
				purchase_detail_log AS d
				CROSS JOIN
				purchase_id_count AS p
		)
		, product_pair_with_stat AS (
			SELECT
				l1.product_id AS p1
				, l2.product_id AS p2
				, l1.product_count AS p1_count
				, l2.product_count AS p2_count
				, COUNT(1) AS p1_p2_count
				, l1.purchase_count AS purchase_count
			FROM
				purchase_detail_log_with_counts AS l1
				JOIN
				purchase_detail_log_with_counts AS l2
				ON l1.purchase_id = l2.purchase_id
			WHERE l1.product_id <> l2.product_id
			GROUP BY 
				l1.product_id, l2.product_id, l1.product_count, l2.product_count, l1.purchase_count
		)

		SELECT 
			*
			, 100.0 * p1_p2_count / purchase_count AS support
			, 100.0 * p1_p2_count / p1_count AS confidence
			-- 100을 곱해주지 않으면 분모가 0이 되어 오류 발생.
			, (100.0 * p1_p2_count / p1_count) / (100.0 * p2_count / purchase_count) AS lift
		FROM product_pair_with_stat
		ORDER BY p1, p2
		;		
		```

3. 추천	
	- 넓게 추천을 '사용자에게 가치 있는 정보를 추천하는 것'으로 정의하자.
	
	1) 추천 시스템의 넓은 의미
		- 추천 시스템의 종류
			+ Item to Item : 열람/구매한 아이템을 기반으로 다른 아이템을 추천해주는 시스템
			+ User to Item : 과거의 행동 또는 데모그래픽 정보를 기반으로 흥미와 기호를 유추하고 아이템을 추천하는 시스템.
		- 추천 모듈의 종류
			+ 리마인드 : 사용자의 과거 행동을 기반으로 아이템을 다시 제안. ex) 최근 본 상품, 재구매하기
			+ 순위 : 열람 수, 구매 수 등을 기반으로 인기 있는 아이템을 제안. ex) 인기 순위, 급상승 순위
			+ 콘텐츠베이스 : 아이템의 추가 정보를 기반으로 다른 아이템을 추천. ex) 해당 배우가 출연한 다른 작품
			+ 추천 : 사용자 전체의 행동 이력을 기반으로 다음에 볼만한 아이템, 관련 아이템을 추측해 제안. ex) 다른 사용자들이 함께 본 상품.
			+ 개별 추천 : 사용자 개인의 행동 이력을 기반으로 흥미 기호를 추측하고 흥미 있어 할만한 아이템을 제안. ex) 당신만을 위한 추천
		- 추천의 효과
			+ 사용자가 가치 있는 정보를 쉽게 접할 수 있도록.
			+ 다운셀 : 가격이 높아 구매를 고민하는 사용자에게 더 저렴한 아이템을 제안해서 구매 수를 올리는 것. ex) 햄버거 사이즈 L에서 M으로 변경.
			+ 크로스셀 : 관련 상품을 함께 구매하게 하여 구매 단가를 올리는 것. ex) 햄버거와 감튀
			+ 업셀 : 상위 모델 또는 고성능의 아이템을 제안하여 구매 단가를 올리는 것. ex) 햄버거 사이즈 M에서 L로 변경
		- 어떤 데이터를 기반으로 추천 시스템을 구축할 것인가?
			+ 암묵적 데이터 
				* 사용자의 행동을 기반으로 기호를 추측. 구매했다면 해당 상품에 기호가 있을 것이라고 판단. 
				* 그러나 반드시 기호와 이어지는지 불분명하다. ex) 영화 시청 했지만 재미없었다.
				* 데이터양은 많으나 정확도가 떨어질 수 있다.
				* 구매 로그 : 함께 구매 가능한 상품을 추천해서 구매 단가를 올릴 수 있다.
				* 열람 로그 : 사용자가 열람한 특정 아이템과 유사한 아이템을 추천해서 사용자의 선택지를 늘린다. 
			+ 명시적 데이터
				* 사용자에게 직접 기호를 물어보아 얻는 데이터
				* 데이터 양이 적지만 평가의 정확성이 높다.
				* 별점 주기.
			
	2) 특정 아이템에 흥미가 있는 사람이 함께 찾아보는 아이템 검색 -> Item to Item
		- 아이템끼리의 상관도를 계산
		
		```sql
		WITH
		ratings AS (
			SELECT
				user_id
				, product
				, SUM(CASE WHEN action='view' THEN 1 ELSE 0 END) AS view_count
				, SUM(CASE WHEN action='purchase' THEN 1 ELSE 0 END) AS purchase_count
				-- 열람수와 구매수를 3:7의 비율로 가중치 평균을 통해 각 아이템에 대한 흥미를 수치화
				, 0.3 * SUM(CASE WHEN action='view' THEN 1 ELSE 0 END) + 0.7 * SUM(CASE WHEN action='purchase' THEN 1 ELSE 0 END)
					AS score
			FROM action_log
			GROUP BY user_id, product
		)

		SELECT
			r1.product AS target
			, r2.product AS related
			, COUNT(r1.user_id) AS users
			-- 아이템 사이의 유사도를 계산. 
			-- '벡터의 내적'값으로 유사도를 정의.
			, SUM(r1.score * r2.score) AS score
			, ROW_NUMBER() OVER(PARTITION BY r1.product ORDER BY SUM(r1.score * r2.score) DESC) AS rank
		FROM 
			ratings AS r1
			JOIN
			ratings AS r2
			ON r1.user_id = r2.user_id
		WHERE r1.product <> r2.product
		GROUP BY r1.product, r2.product
		ORDER BY target, rank
		;		
		```
		
		- 그러나 벡터 내적을 사용한 유사도는 정밀도에 문제가 발생.
			+ 접근 수가 많은 아이템의 유사도가 높게 나온다. (sum)
			+ 점수의 값이 어느 정도의 유사도를 나타내는지 어렵다. 정확한 기준이 없기 때문.
		- 위 문제를 해결하기 위해 '벡터 정규화' 사용
			+ 벡터 정규화 : 벡터를 모두 같은 길이로 만드는 것. 즉 norm을 1로.
			
		```sql
		WITH
		ratings AS (
			SELECT
				user_id
				, product
				, SUM(CASE WHEN action='view' THEN 1 ELSE 0 END) AS view_count
				, SUM(CASE WHEN action='purchase' THEN 1 ELSE 0 END) AS purchase_count
				-- 열람수와 구매수를 3:7의 비율로 가중치 평균을 통해 각 아이템에 대한 흥미를 수치화
				, 0.3 * SUM(CASE WHEN action='view' THEN 1 ELSE 0 END) + 0.7 * SUM(CASE WHEN action='purchase' THEN 1 ELSE 0 END)
					AS score
			FROM action_log
			GROUP BY user_id, product
		)
		, product_base_normalized_ratings AS (
			SELECT
				user_id
				, product
				, score
				, SQRT(SUM(score*score) OVER(PARTITION BY product)) AS norm
				, score / SQRT(SUM(score*score) OVER(PARTITION BY product)) AS norm_score
			FROM ratings
		)

		SELECT
			r1.product AS target
			, r2.product AS related
			, COUNT(r1.user_id) AS users
			-- 아이템 사이의 유사도를 계산. 
			, SUM(r1.norm_score * r2.norm_score) AS norm_score
			, ROW_NUMBER() OVER(PARTITION BY r1.product ORDER BY SUM(r1.norm_score * r2.norm_score) DESC) AS rank
		FROM 
			product_base_normalized_ratings AS r1
			JOIN
			product_base_normalized_ratings AS r2
			ON r1.user_id = r2.user_id
		WHERE r1.product <> r2.product
		GROUP BY r1.product, r2.product
		ORDER BY target, rank
		;		
		```
		
	3) 당신을 위한 추천 상품 -> User to Item
		- 사용자와 사용자의 유사도를 계산 후에, 유사 사용자가 흥미를 가진 아이템을 구한다.
		
		```sql
		WITH
		ratings AS (
			SELECT
				user_id
				, product
				, SUM(CASE WHEN action='view' THEN 1 ELSE 0 END) AS view_count
				, SUM(CASE WHEN action='purchase' THEN 1 ELSE 0 END) AS purchase_count
				-- 열람수와 구매수를 3:7의 비율로 가중치 평균을 통해 각 아이템에 대한 흥미를 수치화
				, 0.3 * SUM(CASE WHEN action='view' THEN 1 ELSE 0 END) + 0.7 * SUM(CASE WHEN action='purchase' THEN 1 ELSE 0 END)
					AS score
			FROM action_log
			GROUP BY user_id, product
		)
		, user_base_normalized_ratings AS (
			-- 사용자별로 벡터 정규화를 이용하여 norm_score 구하기
			SELECT
				user_id
				, product
				, score
				, SQRT(SUM(score*score) OVER(PARTITION BY user_id)) AS norm
				, score / SQRT(SUM(score*score) OVER(PARTITION BY user_id)) AS norm_score
			FROM ratings
		)
		, related_users AS (
			-- 관련있는 사용자 구하기
			SELECT
				r1.user_id
				, r2.user_id AS related_user
				, COUNT(r1.product) AS products
				, SUM(r1.norm_score * r2.norm_score) AS score
				, ROW_NUMBER() OVER(PARTITION BY r1.user_id ORDER BY SUM(r1.norm_score*r2.norm_score) DESC) AS rank

			FROM 
				user_base_normalized_ratings AS r1
				JOIN
				user_base_normalized_ratings AS r2
				ON r1.product = r2.product
			WHERE r1.user_id <> r2.user_id
			GROUP BY r1.user_id, r2.user_id
		)
		, related_user_base_products AS (
			-- 유사 사용자가 흥미있어하는 아이템 추출
			SELECT
				u.user_id
				, r.product
				, SUM(u.score*r.norm_score) AS score
				, ROW_NUMBER() OVER(PARTITION BY u.user_id ORDER BY SUM(u.score*r.norm_score) DESC) AS rank
			FROM 
				related_users AS u
				JOIN
				-- 왜 교재에서는 normalized score안쓰고 그냥 score로 썼을까.
				user_base_normalized_ratings AS r
				ON u.related_user = r.user_id
			WHERE u.rank <= 1	
			GROUP BY u.user_id, r.product
		)

		SELECT 
			p.user_id
			, p.product
			, p.score
			, ROW_NUMBER() OVER(PARTITION BY p.user_id ORDER BY p.score DESC) AS rank
		FROM 
			related_user_base_products AS p
			LEFT JOIN
			ratings AS r
			ON p.user_id = r.user_id AND p.product = r.product
		WHERE COALESCE(r.purchase_count, 0) = 0
		ORDER BY p.user_id
		;		
		```
		
	4) 추천 시스템을 개선할 때의 포인트
		- 서비스 사용자가 원하는 정보와 예측한 내용, 서비스 사용자가 원하는 것 등이 일치할 때 최적의 효과를 발휘. => 정밀도를 높여보자
		+ 값과 리스트 조작에서 개선할 포인트
			- 가중치 : 여러 데이터가 있을 때 어느 데이터에 더 가중치를 줄 것인지
			- 필터 : 비정상적인 로그는 제외하고, 사용자의 데모그래픽 정보를 기반으로 필터하면 좋다.
			- 정렬 : 목적에 따라 지표를 달리하고, 이 지표 값을 정렬해서 추천하면 좋다.
		+ 구축 방법에 따른 개선 포인트
			- 데이터 수집 : 다양한 데이터를 사용하면 정밀도를 높일 수 있다. 
			- 데이터 가공 : 점수를 계산하기 쉬운 형태로. 비정상적인 데이터는 제외. 유행을 고려한 평가 기간을 정하거나.
			- 데이터 계산 : 순위를 구하는 로직.
			- 데이터 정렬 : 필터 또는 정렬 기능 추가.
		
	5) 출력할 때의 포인트
		- 출력 페이지, 위치, 시점 검토하기 : 각 목적에 따라 위치시키기.
		- 추천의 이유 : '추천 상품'이라고 명시하기 보다 '이 상품을 구매한 사람은 이러한 상품도 구매했습니다'와 같이 추천이유를 명확하게 전달하기.
		- 크로스셀을 염두한 추천하기 : 함께 자주 구매되는 상품을 같이 구매하기 편하도록.
		- 서비스와 함께 제공하기 : 구매 금액 일정 이상일 때 무료배송
	6) 추천과 관련한 지표
		- Microsoft Research 기술 리포트 중 Shani Guy가 작성한 'Evaluating Recommender Systems(2009)' 참고
			+ Coverage : 전체 중 추천이 제공되는 사용자와 아이템의 비율
			+ Confidence : 시스템적인 추천 아이템의 신뢰도. 데이터양이 많으면 높은 값을 가짐.
			+ Trust : 사용자적인 추천아이템의 신뢰도. 사용자에게 추천이 제대로 되는지 물어봄으로써 얻는 지표.
			+ Novelty : 추천 아이템의 신규성.
			+ Serendipity : 뜻밖의 아이템을 추천하는지
			+ Diversity : 추천된 아이템의 다양성
			+ Utility : 서비스 추천의 유익성
			+ Risk : 리스크를 포함한 아이템(주식)을 추천할 때 고려해야함.
			+ Robustness : DOS 공격 등이 있을 때 추천 내용이 왜곡되지는 않는지.
			+ Privacy : 추천 내용을 통해 개인 정보를 추측할 수 있는지
			+ Adaptivity : 아이템이 업데이터와 유행 등의 변화에 잘 대응할 수 있는지.
			+ Scalability : 데이터의 양이 늘어났을 때 대응할 수 있는지.

4. 점수 계산하기
	1) 여러 값을 균형있게 조합해서 점수 계산하기
		- 데이터 분석 시 여러 지표를 비교하면서 종합적으로 판단해야한다.
		- 산술 평균
			+ sum(a,b) / count(a,b)
		- 기하 평균
			+ (ab)^(1/count(a,b)) 
			+ 여러번 지표를 곱해야하는 경우. 성장률, 이율 등을 구할 때
		- 조화 평균
			+ avg(1/a, 1/b) -> 역수
			+ 비율을 나타내는 값의 평균을 계산할 때. 평균 속도 계산.
		- a=b일 경우, 산술 평균 = 기하 평균 = 조화 평균
		- a<>b일 경우, 산술 평균 > 기하 평균 > 조화 평균 
		
		```sql
		-- 여러 값을 조합한 뒤 집약해서 비교, 검토
		-- -> 재현율과 적합률을 조합해서 검색 엔진의 정밀도를 평가하기
		
		-- 세로 데이터
		SELECT
			*
			, (recall+precision) / 2 AS arithmetic_mean
			, POWER(recall*precision, 1.0/2) AS geometric_mean
			, 2.0 / ((1.0/recall) + (1.0/precision)) AS harmoinc_mean
		FROM search_evaluation_by_col
		WHERE recall*precision >0
		ORDER BY path
		;
		
		-- 가중 평균
		SELECT
			*
			, 0.3 * recall + 0.7 * precision AS arithmetic_mean
			, POWER(recall, 0.3) * POWER(precision, 0.7) AS geometric_mean
			, 1.0 / ((0.3/recall) + (0.7/precision)) AS harmoinc_mean
		FROM search_evaluation_by_col
		WHERE recall*precision >0
		ORDER BY path
		;
		```
		
		```sql
		-- 가로 데이터
		SELECT
			path
			, AVG(value) AS weighted_arithmetic_mean
			, POWER(10, AVG(log(value))) AS weighted_geometric_mean
			, 1.0 / (AVG(1.0 / value)) AS weighted_harmoinc_mean
		FROM search_evaluation_by_row
		WHERE value >0
		GROUP BY path
		HAVING COUNT(*) = 2
		ORDER BY path
		;
		
		-- 가중 평균
		WITH
		weights AS (
			SELECT 'recall' AS index, 0.3 AS weight
			UNION ALL SELECT 'precision' AS index, 0.7 AS weight
		)

		SELECT
			e.path
			, SUM(w.weight * e.value) AS weighted_arithmetic_mean
			, POWER(10, SUM(w.weight * log(e.value))) AS weighted_geometric_mean
			, 1.0 / SUM(w.weight / e.value) AS weighted_harmoinc_mean
		FROM 
			search_evaluation_by_row AS e
			JOIN
			weights AS w
			ON e.index = w.index
		WHERE e.value > 0
		GROUP BY e.path
		HAVING COUNT(*) = 2
		ORDER BY e.path
		;
		```
		
	2) 값의 범위가 다른 지표를 정규화해서 비교 가능한 상태로 만들기
		- 위에서 평균을 구했지만 값의 범위가 다른 경우에는 정규화를 통해 비교 가능하도록 만들어야한다.
		- Min-Max 정규화 : (값-Min) / (Max-Min)
			
			```sql
			SELECT 
				user_id
				, product
				, view_count AS v_count
				, purchase_count AS norm_p_count
				, 1.0 * (view_count - MIN(view_count) OVER()) 
					/ NULLIF((MAX(view_count) OVER() - MIN(view_count) OVER()), 0)
					AS norm_v_count
			FROM action_counts
			ORDER BY user_id, product
			;
			```
			
		- 시그모이드 함수로 변환하기
			+ 결괏값이 0~1인 함수 중 시그모이드 함수가 많이 사용된다.
			+ Min-Max 정규화는 1 최댓값, 최솟값을 찾아야 되는 문제. 2 정규화 후의 값들이 모두 변하는 문제.
			+ 비선형적인 변환으로 0값에 가까울수록 변환값의 영향이 크다.
			
			```sql
			SELECT
				user_id
				, product
				, view_count AS v_count
				, purchase_count AS p_count
				, 2.0 / (1+exp(-0.1 * view_count)) - 1.0 AS sigm_v_count
				, 2.0 / (1+exp(-0.1 * purchase_count)) - 1.0 AS sigm_p_count
			FROM action_counts
			ORDER BY user_id, product
			;			
			```
			
	3) 각 데이터의 편차값 계산하기
		- 표준편차 
			+ 데이터의 쏠림 상태를 나타내는 값
			+ 값이 커질수록 데이터에 쏠림이 있다.
		- 정규값
			+ 평균으로부터 얼마나 떨어져있는가. 쏠림 정도를 기반으로 데이터를 변화하는 것.
		- 편차값 
			+ 편차값 = 정규값 * 10 + 50
			+ 평균은 50, 표준편차는 10
		
		```sql
		SELECT
			subject
			, name
			, score
			, stddev_pop(score) OVER(PARTITION BY subject) AS stddev_pop
			, AVG(score) OVER(PARTITION BY subject) AS avg_score
			, (score-AVG(score) OVER(PARTITION BY subject)) / stddev_pop(score) OVER(PARTITION BY subject)
				AS std_value --정규값
			, 10.0 * (score-AVG(score) OVER(PARTITION BY subject)) / stddev_pop(score) OVER(PARTITION BY subject) + 50
				AS deviation --편차값
		FROM exam_scores
		ORDER BY subject, name
		;		
		```
		
	4) 거대한 숫자 지표를 직감적으로 이해하기 쉽게 가공하기 -> 로그 변환
		- 값이 크면 클수록 값 차이가 큰 영향을 주지 않는 경우.
		
		```sql
		WITH
		action_counts_with_diff_date AS (
			SELECT *
				, MAX(dt::date) OVER(PARTITION BY user_id) AS last_access
				, MAX(dt::date) OVER(PARTITION BY user_id) - dt::date AS diff_date
				-- 마지막 접속일과의 날짜 차이가 클수록 값 차이가 큰 영향을 주지 않음.
			FROM action_counts_with_date
		)
		, action_counts_with_weight AS (
			SELECT *
				, 1.0 / log(2, 0.1*diff_date+2) AS weight
			FROM action_counts_with_diff_date
		)
		, action_scores AS (
			-- 마지막 접속일과의 날짜 차이를 weight로 해서 지표를 계산
			SELECT
				user_id
				, product
				, SUM(v_count) AS v_count
				, SUM(v_count * weight) AS v_score
				, SUM(p_count) AS p_count
				, SUM(p_count * weight) AS p_score
			FROM action_counts_with_weight
			GROUP BY user_id, product
		)
		SELECT *
		FROM action_scores
		ORDER BY user_id, product
		;		
		```
		
	5) 독자적인 점수 계산 방법을 정의해서 순위 작성하기

		```sql
		WITH
		item_sales_per_quarters AS (
			SELECT
				item
				, SUM(CASE WHEN year_month IN ('2016-01', '2016-02', '2016-03') THEN amount ELSE 0 END) AS sales_2016_q1
				, SUM(CASE WHEN year_month IN ('2016-10', '2016-11', '2016-12') THEN amount ELSE 0 END) AS sales_2016_q4
			FROM monthly_sales
			GROUP BY item
		)
		, item_scores_per_quarters AS (
			-- 분기별로 점수 정규화(min-max정규화)
			SELECT
				item
				, sales_2016_q1
				, 1.0 * (sales_2016_q1 - MIN(sales_2016_q1) OVER())
					/ NULLIF(MAX(sales_2016_q1) OVER() - MIN(sales_2016_q1) OVER(), 0)
					AS score_2016_q1
				, sales_2016_q4
				, 1.0 * (sales_2016_q4 - MIN(sales_2016_q4) OVER())
					/ NULLIF(MAX(sales_2016_q4) OVER() - MIN(sales_2016_q4) OVER(), 0)
					AS score_2016_q4
			FROM item_sales_per_quarters
		)

		SELECT 
			item
			-- 서비스 전체의 매출이 상승 경향을 보이기 때문에 7:3으로 가중치를 설정
			, 0.7 * score_2016_q1 + 0.3 * score_2016_q4 AS score
			, ROW_NUMBER() OVER(ORDER BY 0.7 * score_2016_q1 + 0.3 * score_2016_q4 DESC) AS rank
		FROM item_scores_per_quarters
		ORDER BY rank
		;		
		```
